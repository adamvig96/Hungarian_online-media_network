{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import requests\n",
    "import ast  # for string to list: ast.literal_eval()\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/vigadam/Dropbox/My Mac (MacBook-Air.local)/Documents/github/media_network/media_data/clean_text/2020/\"\n",
    "files = os.listdir(data_dir)\n",
    "files.sort()\n",
    "files.remove(\"covid_monthly_444origo.csv\")\n",
    "data_files = [data_dir + file for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/vigadam/Dropbox/My Mac (MacBook-Air.local)/Documents/github/media_network/media_data/clean_text/2020/all_site_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month\"]=df[\"date\"].str.split(\"-\").apply(lambda x: x[1])\n",
    "df[\"day\"]=df[\"date\"].str.split(\"-\").apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 224293/224293 [21:37<00:00, 172.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(df.shape[0])):\n",
    "    if len(df.loc[i,\"month\"]) == 1:\n",
    "        df.loc[i,\"month\"] = \"0\" + df.loc[i,\"month\"]\n",
    "    if len(df.loc[i,\"day\"]) == 1:\n",
    "        df.loc[i,\"day\"] = \"0\" + df.loc[i,\"day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"]=df[\"year\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = df.agg('{0[year]}-{0[month]}-{0[day]}'.format, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10    224293\n",
       "Name: date, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "df[\"date\"].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/vigadam/Dropbox/My Mac (MacBook-Air.local)/Documents/github/media_network/media_data/clean_text/2020/all_site_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['link', 'rovat', 'date', 'year', 'month', 'page', 'Title', 'Text',\n",
      "       'Author', 'Tags'],\n",
      "      dtype='object')\n",
      "Index(['link', 'year', 'date', 'month', 'page', 'Title', 'Text', 'links',\n",
      "       'Author', 'Category', 'Tags'],\n",
      "      dtype='object')\n",
      "Index(['link', 'rovat', 'Title', 'Text', 'Author', 'date', 'Tags'], dtype='object')\n",
      "Index(['datum', '_mod_ts', '__properties', 'rovat', 'rovat_url', 'rovat_slug',\n",
      "       'kiadvany', 'kiadvany_url', 'tags', 'actual_fb_like', 'ts', 'kep',\n",
      "       'cim', 'ajanlo', 'alcim', 'url', 'korhatar_stamp', 'alnevek', 'lead',\n",
      "       'month', 'page', 'Text', 'Author', 'Tags'],\n",
      "      dtype='object')\n",
      "Index(['link', 'rovat', 'felosztas', 'Title', 'links', 'Author', 'Text',\n",
      "       'year', 'month', 'day', 'Tags', 'Source'],\n",
      "      dtype='object')\n",
      "Index(['link', 'date', 'month', 'rovat', 'page', 'Title', 'Text', 'links',\n",
      "       'Author', 'Tags'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for file in data_files:\n",
    "    df = pd.read_csv(file,index_col=0)\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "_24hu = pd.read_csv(data_files[0],index_col=0)[[\"link\",\"rovat\",\"date\",\"page\",\"Title\",\"Text\",\"Author\",\"Tags\"]].rename(columns={\"rovat\":\"category\"})\n",
    "_24hu.columns = [item.lower() for item in _24hu.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "_444 = pd.read_csv(data_files[1],index_col=0)[[\"link\",\"Category\",\"date\",\"page\",\"Title\",\"Text\",\"Author\",\"Tags\"]]\n",
    "_444.columns = [item.lower() for item in _444.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "_888 = pd.read_csv(data_files[2],index_col=0)[[\"link\",\"rovat\",\"date\",\"Title\",\"Text\",\"Author\",\"Tags\"]].rename(columns={\"rovat\":\"category\"})\n",
    "\n",
    "\n",
    "_888[\"page\"] = \"888\"\n",
    "_888.columns = [item.lower() for item in _888.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv(data_files[3],index_col=0).drop(columns=[\"tags\"]).rename(columns={\"rovat\":\"category\",\"url\":\"link\",\"_mod_ts\":\"date\",\"cim\":\"title\"}).reset_index(drop=True)\n",
    "index.columns = [item.lower() for item in index.columns]\n",
    "\n",
    "index = index[[\"link\",\"date\",\"category\",\"title\",\"author\",\"text\",\"tags\",\"page\"]]\n",
    "\n",
    "index[\"date\"] = index[\"date\"].str.split(\" \").apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 45157/45157 [03:53<00:00, 193.55it/s]\n"
     ]
    }
   ],
   "source": [
    "mno = pd.read_csv(data_files[4],index_col = 0)\n",
    "mno.columns = [item.lower() for item in mno.columns]\n",
    "mno = mno.rename(columns={\"rovat\":\"category\"}).dropna(subset=[\"text\",\"year\"]).reset_index(drop=True)\n",
    "\n",
    "mno[\"year\"] = mno[\"year\"].apply(int).apply(str)\n",
    "mno[\"month\"] = mno[\"month\"].apply(int).apply(str)\n",
    "mno[\"day\"] = mno[\"day\"].apply(int).apply(str)\n",
    "\n",
    "for i in tqdm(range(mno.shape[0])):\n",
    "    mno.loc[i,\"date\"] = \"-\".join([mno.loc[i,\"year\"],mno.loc[i,\"month\"],mno.loc[i,\"day\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "mno = mno[[\"link\",\"date\",\"category\",\"title\",\"author\",\"text\",\"tags\"]]\n",
    "mno[\"page\"] = \"mno\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "origo = pd.read_csv(data_files[5],index_col = 0).rename(columns={\"rovat\":\"category\"})\n",
    "origo.columns = [item.lower() for item in origo.columns]\n",
    "origo = origo[[\"link\",\"date\",\"category\",\"title\",\"author\",\"text\",\"tags\",\"page\"]]\n",
    "origo[\"date\"] = origo[\"date\"].apply(lambda x: str(x)[0:4] + \"-\" + str(x)[4:6] +\"-\"+ str(x)[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites = pd.concat([_24hu,index,origo,_444,_888,mno])\n",
    "all_sites[\"page\"]=all_sites[\"page\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "link            0\n",
       "category        0\n",
       "date            0\n",
       "page            0\n",
       "title       15339\n",
       "text        26094\n",
       "author      33743\n",
       "tags        29091\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 196
    }
   ],
   "source": [
    "all_sites.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites[\"year\"] = all_sites[\"date\"].str.split(\"-\").apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites = all_sites.loc[all_sites[\"year\"] == \"2020\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites.to_csv(data_dir + \"all_site_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Users/vigadam/Dropbox/My Mac (MacBook-Air.local)/Documents/github/media_network/media_data/clean_text/2020/'"
      ]
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "külföld          3993\n",
       "politika         1965\n",
       "egészségügy      1482\n",
       "bűnügy           1023\n",
       "járvány           853\n",
       "                 ... \n",
       "kereszténység       1\n",
       "tömeg               1\n",
       "demográfia          1\n",
       "media               1\n",
       "mik vannak?!        1\n",
       "Name: category, Length: 249, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby([\"Page\",\"Author\"])[\"Link\"].count().reset_index().sort_values(by=\"Link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Author</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>888</td>\n",
       "      <td>Bohár Dániel</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>888</td>\n",
       "      <td>888.hu - V4NA</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>888</td>\n",
       "      <td>Filipp Dávid</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>888</td>\n",
       "      <td>888 / MTI</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>888</td>\n",
       "      <td>Pozsonyi Ádám</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>888</td>\n",
       "      <td>MTI, 888.hu</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>888</td>\n",
       "      <td>Horváth K. József</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>888</td>\n",
       "      <td>M. Kovács Róbert</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>888</td>\n",
       "      <td>888.hu ; MTI</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>888</td>\n",
       "      <td>888.hu/MTI</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>888</td>\n",
       "      <td>Békési Marcell</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>888</td>\n",
       "      <td>888, MTI</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>888</td>\n",
       "      <td>Horváth Tamás</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>888</td>\n",
       "      <td>MTI</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>888</td>\n",
       "      <td>Ányos Miklós</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>888</td>\n",
       "      <td>888.hu - MTI</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>888</td>\n",
       "      <td>888.hu</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Page             Author  Link\n",
       "188  888       Bohár Dániel    11\n",
       "160  888      888.hu - V4NA    12\n",
       "193  888       Filipp Dávid    17\n",
       "148  888                888    23\n",
       "150  888          888 / MTI    29\n",
       "220  888      Pozsonyi Ádám    31\n",
       "217  888        MTI, 888.hu    31\n",
       "198  888  Horváth K. József    42\n",
       "213  888   M. Kovács Róbert    51\n",
       "167  888       888.hu ; MTI    55\n",
       "181  888         888.hu/MTI    57\n",
       "189  888     Békési Marcell    58\n",
       "154  888           888, MTI    64\n",
       "199  888      Horváth Tamás    90\n",
       "215  888                MTI   131\n",
       "229  888       Ányos Miklós   208\n",
       "158  888       888.hu - MTI   368\n",
       "156  888             888.hu   508"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.query(\"(Page == '888')&(Link > 10)\").tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helper:\n",
    "    import json\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    import bs4\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    import re\n",
    "\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    def __init__(self, df):\n",
    "        None\n",
    "\n",
    "    def title_main(self, element, id):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = (\n",
    "                    BeautifulSoup(soup).find(element, id=id).find(\"h1\").get_text()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = None\n",
    "\n",
    "    def link(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            soup_for_links = BeautifulSoup(soup).find_all(\"a\")\n",
    "            link_list = []\n",
    "            for item in soup_for_links:\n",
    "                if type(item.get(\"href\")) == str:\n",
    "                    link_list.append(item.get(\"href\"))\n",
    "            df.loc[self.soups.index[i], \"Links\"] = str(list(set(link_list)))\n",
    "\n",
    "    def text_main(self, element, class_id):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                soup_for_text = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(element, class_=re.compile(class_id))\n",
    "                    .find_all(\"p\")\n",
    "                )\n",
    "                text_list = []\n",
    "                for item in soup_for_text:\n",
    "                    if soup_for_text != \"\":\n",
    "                        text_list.append(item.text)\n",
    "                df.loc[self.soups.index[i], \"Text\"] = \" \".join(text_list)\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Text\"] = None\n",
    "\n",
    "    def author_main(self, element, class_id):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(element, class_=class_id)\n",
    "                    .get_text()\n",
    "                    .strip()\n",
    "                )\n",
    "            except:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = None\n",
    "\n",
    "    def clean(self):\n",
    "        self.title()\n",
    "        self.text()\n",
    "        self.link()\n",
    "        self.author()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mainekre returnt tenni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_444\n",
    "Mandiner\n",
    "Origo\n",
    "_24\n",
    "Ripost\n",
    "_888\n",
    "Figyelo\n",
    "VilagGazdasag\n",
    "Napi\n",
    "Alfahir\n",
    "Index\n",
    "HVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _444(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"444\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"headline\")\n",
    "\n",
    "    def link(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            if len(BeautifulSoup(soup).find_all(\"article\")) != 0:\n",
    "                soup_for_links = (\n",
    "                    BeautifulSoup(soup).find_all(\"article\")[0].find_all(\"a\")\n",
    "                )\n",
    "                link_list = []\n",
    "                for item in soup_for_links:\n",
    "                    if type(item.get(\"href\")) == str:\n",
    "                        link_list.append(item.get(\"href\"))\n",
    "                df.loc[self.soups.index[i], \"Links\"] = str(list(set(link_list)))\n",
    "            else:\n",
    "                df.loc[self.soups.index[i], \"Links\"] = []\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"main\", \"col-xs-12 col-md-8 col-lg-7\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"span\", \"byline__authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mandiner(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Mandiner\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"article\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"articletext\")\n",
    "\n",
    "    def author(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(\"span\", style=\"text-transform: uppercase; font-weight: 700\")\n",
    "                    .get_text()\n",
    "                    .strip()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Origo(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Origo\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"header\", \"article-head\")\n",
    "\n",
    "    def text(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                soup_for_text = (\n",
    "                    BeautifulSoup(soup).find(\"div\", id=\"article-text\").find_all(\"p\")\n",
    "                )\n",
    "                text_list = []\n",
    "                for item in soup_for_text:\n",
    "                    if soup_for_text != \"\":\n",
    "                        text_list.append(item.text)\n",
    "                df.loc[self.soups.index[i], \"Text\"] = \" \".join(text_list)\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Text\"] = None\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"span\", \"article-author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _24(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"24.hu\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"content\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"o-post__body o-postCnt post-body\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"div\", \"m-author__authorLinkWrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ripost(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Ripost\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"contentholderall\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"content-holder\")\n",
    "\n",
    "    def author(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(\"a\", style=\"text-decoration:none;\")\n",
    "                    .get_text()\n",
    "                    .strip()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _888(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"888\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"cikkholder\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"maincontent8\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"div\", \"note-block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Figyelo(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Figyelő\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"article-title\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"entry-content clearfix\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"span\", \"news__author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VilagGazdasag(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Világgazdaság\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"content-area\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"entry-content clearfix\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"span\", \"enews-article-author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Napi(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Napi.hu\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(\"div\", class_=\"article\")\n",
    "                    .find(\"h1\")\n",
    "                    .get_text()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = None\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"article\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"a\", \"GAHitCounter bl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alfahir(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Alfahír\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = (\n",
    "                    BeautifulSoup(soup).find(\"h1\", class_=\"page-title\").get_text()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = None\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"article-content\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(\n",
    "            self,\n",
    "            \"div\",\n",
    "            \"field field--name-username field--type-ds field--label-hidden field--item\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Index\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"content\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"cikk-torzs\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"div\", \"szerzok_container\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HVG(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"HVG\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"perspective\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"article-menu_main\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"div\", \"author-name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}