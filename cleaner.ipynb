{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import requests\n",
    "import ast  # for string to list: ast.literal_eval()\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"data/\")\n",
    "files.sort()\n",
    "files.remove(\".DS_Store\")\n",
    "files.remove(\"links_soups_2020-06-18.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [46:34<00:00, 45.07s/it]\n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame()\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_pickle(\"data/\" + file).reset_index(drop=True)\n",
    "\n",
    "    _444(df).author()\n",
    "    Mandiner(df).author()\n",
    "    Origo(df).author()\n",
    "    _24(df).author()\n",
    "    Ripost(df).author()\n",
    "    _888(df).author()\n",
    "    Figyelo(df).author()\n",
    "    VilagGazdasag(df).author()\n",
    "    Napi(df).author()\n",
    "    Alfahir(df).author()\n",
    "    Index(df).author()\n",
    "    HVG(df).author()\n",
    "\n",
    "    out = (\n",
    "        pd.concat([out, df[df.columns.difference([\"Soup\"])]])\n",
    "        .reset_index(drop=True)\n",
    "        .drop_duplicates(subset=[\"Link\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"jun-jul-aug.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helper:\n",
    "    import json\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    import bs4\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    import re\n",
    "\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    def __init__(self, df):\n",
    "        None\n",
    "\n",
    "    def title_main(self, element, id):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = (\n",
    "                    BeautifulSoup(soup).find(element, id=id).find(\"h1\").get_text()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = None\n",
    "\n",
    "    def link(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            soup_for_links = BeautifulSoup(soup).find_all(\"a\")\n",
    "            link_list = []\n",
    "            for item in soup_for_links:\n",
    "                if type(item.get(\"href\")) == str:\n",
    "                    link_list.append(item.get(\"href\"))\n",
    "            df.loc[self.soups.index[i], \"Links\"] = str(list(set(link_list)))\n",
    "\n",
    "    def text_main(self, element, class_id):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                soup_for_text = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(element, class_=re.compile(class_id))\n",
    "                    .find_all(\"p\")\n",
    "                )\n",
    "                text_list = []\n",
    "                for item in soup_for_text:\n",
    "                    if soup_for_text != \"\":\n",
    "                        text_list.append(item.text)\n",
    "                df.loc[self.soups.index[i], \"Text\"] = \" \".join(text_list)\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Text\"] = None\n",
    "\n",
    "    def author_main(self, element, class_id):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(element, class_=class_id)\n",
    "                    .get_text()\n",
    "                    .strip()\n",
    "                )\n",
    "            except:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = None\n",
    "\n",
    "    def clean(self):\n",
    "        self.title()\n",
    "        self.text()\n",
    "        self.link()\n",
    "        self.author()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mainekre returnt tenni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_444\n",
    "Mandiner\n",
    "Origo\n",
    "_24\n",
    "Ripost\n",
    "_888\n",
    "Figyelo\n",
    "VilagGazdasag\n",
    "Napi\n",
    "Alfahir\n",
    "Index\n",
    "HVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _444(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"444\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"headline\")\n",
    "\n",
    "    def link(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            if len(BeautifulSoup(soup).find_all(\"article\")) != 0:\n",
    "                soup_for_links = (\n",
    "                    BeautifulSoup(soup).find_all(\"article\")[0].find_all(\"a\")\n",
    "                )\n",
    "                link_list = []\n",
    "                for item in soup_for_links:\n",
    "                    if type(item.get(\"href\")) == str:\n",
    "                        link_list.append(item.get(\"href\"))\n",
    "                df.loc[self.soups.index[i], \"Links\"] = str(list(set(link_list)))\n",
    "            else:\n",
    "                df.loc[self.soups.index[i], \"Links\"] = []\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"main\", \"col-xs-12 col-md-8 col-lg-7\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"span\", \"byline__authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mandiner(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Mandiner\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"article\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"articletext\")\n",
    "\n",
    "    def author(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(\"span\", style=\"text-transform: uppercase; font-weight: 700\")\n",
    "                    .get_text()\n",
    "                    .strip()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Origo(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Origo\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"header\", \"article-head\")\n",
    "\n",
    "    def text(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                soup_for_text = (\n",
    "                    BeautifulSoup(soup).find(\"div\", id=\"article-text\").find_all(\"p\")\n",
    "                )\n",
    "                text_list = []\n",
    "                for item in soup_for_text:\n",
    "                    if soup_for_text != \"\":\n",
    "                        text_list.append(item.text)\n",
    "                df.loc[self.soups.index[i], \"Text\"] = \" \".join(text_list)\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Text\"] = None\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"span\", \"article-author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _24(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"24.hu\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"content\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"o-post__body o-postCnt post-body\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"div\", \"m-author__authorLinkWrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ripost(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Ripost\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"contentholderall\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"content-holder\")\n",
    "\n",
    "    def author(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(\"a\", style=\"text-decoration:none;\")\n",
    "                    .get_text()\n",
    "                    .strip()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Author\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _888(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"888\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"cikkholder\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"maincontent8\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"div\", \"note-block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Figyelo(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Figyelő\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"article-title\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"entry-content clearfix\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"span\", \"news__author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VilagGazdasag(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Világgazdaság\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"content-area\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"entry-content clearfix\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"span\", \"enews-article-author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Napi(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Napi.hu\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = (\n",
    "                    BeautifulSoup(soup)\n",
    "                    .find(\"div\", class_=\"article\")\n",
    "                    .find(\"h1\")\n",
    "                    .get_text()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = None\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"article\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"a\", \"GAHitCounter bl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alfahir(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Alfahír\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        for i, soup in enumerate(self.soups):\n",
    "            try:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = (\n",
    "                    BeautifulSoup(soup).find(\"h1\", class_=\"page-title\").get_text()\n",
    "                )\n",
    "            except AttributeError:\n",
    "                df.loc[self.soups.index[i], \"Title\"] = None\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"article-content\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(\n",
    "            self,\n",
    "            \"div\",\n",
    "            \"field field--name-username field--type-ds field--label-hidden field--item\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"Index\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"content\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"cikk-torzs\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"div\", \"szerzok_container\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HVG(Helper):\n",
    "    def __init__(self, df):\n",
    "        page = \"HVG\"\n",
    "        self.data = df.loc[df[\"Page\"] == page]\n",
    "        self.soups = self.data[\"Soup\"].dropna()\n",
    "\n",
    "    def title(self):\n",
    "        Helper.title_main(self, \"div\", \"perspective\")\n",
    "\n",
    "    def text(self):\n",
    "        Helper.text_main(self, \"div\", \"article-menu_main\")\n",
    "\n",
    "    def author(self):\n",
    "        Helper.author_main(self, \"div\", \"author-name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
